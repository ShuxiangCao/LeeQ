{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d304004-a4e6-45ee-8cbf-ee2aa5f10935",
   "metadata": {},
   "source": [
    "# Inspection Benchmarking\n",
    "\n",
    "In this study we wish to check the AI's ability to check the validity of the data and determine if the experiment has succeeded or not.\n",
    "\n",
    "We generate 100 figures with synthetic data for each experiment. 100 success and different types of failure.\n",
    "\n",
    "We report the correctness with 1: only fitting 2: only vision model 3: vision model + fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30c19938-f651-492e-acaa-e8627ac7e3ff",
   "metadata": {},
   "source": [
    "from benchmarks import *"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b31e02e3-b653-485c-9a01-92f6409b99bc",
   "metadata": {},
   "source": [
    "\n",
    "num_samples = 1\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37cb2f2a-0d29-4db0-a7c9-91ec0f97c73e",
   "metadata": {},
   "source": [
    "model = 'openai'\n",
    "benchmark_name='gmm'\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccca6a32-f714-483d-88da-77f02ce0804a",
   "metadata": {},
   "source": [
    "from mllm.provider_switch import *\n",
    "# set_default_to_anthropic()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0af187d4-4824-491f-ba0f-a8d063c038b3",
   "metadata": {},
   "source": [
    "## GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7d8d66e-9802-4022-9b95-2058889c0bf8",
   "metadata": {},
   "source": [
    "# Success\n",
    "config='success'\n",
    "\n",
    "run_benchmarks(save_path_prefix=rf'./{model}_{benchmark_name}_{config}_cases',\n",
    "    num_samples=num_samples,\n",
    "    benchmark_func=run_single_benchmark_gmm, \n",
    "    config_key='success',\n",
    "    extra_config = {\n",
    "        'AIAutoInspectPlots':True,\n",
    "        'Plot_Result_In_Jupyter':True\n",
    "    }\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96933def-5422-4357-91b3-e592671a552b",
   "metadata": {},
   "source": [
    "# Failure\n",
    "config='failure'\n",
    "\n",
    "run_benchmarks(save_path_prefix=rf'./{model}_{benchmark_name}_{config}_cases',\n",
    "    num_samples=num_samples,\n",
    "    benchmark_func=run_single_benchmark_gmm, \n",
    "    config_key='failure',\n",
    "    extra_config = {\n",
    "        'AIAutoInspectPlots':True,\n",
    "        'Plot_Result_In_Jupyter':True\n",
    "    }\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdf10e3-a1c3-4e4b-a97a-b02cb3333311",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
