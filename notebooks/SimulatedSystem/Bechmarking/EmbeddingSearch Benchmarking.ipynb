{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4ddbac9-5705-48d9-a00e-4663dc6346ff",
   "metadata": {},
   "source": [
    "# Embedding Search Benchmarking\n",
    "\n",
    "In this study we wish to check the AI's ability to understand the natural language description of the experiment and select the correct experiment from the code base.\n",
    "\n",
    "We generate 10 different prompts for each experiment and check if the AI can find the correct related experiment.\n",
    "\n",
    "We report the accuracy of top hit, top 3 hit, top 5 hit and hit after filtering and revision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7fb004-5eca-418b-a462-b149a43619f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T20:30:31.491892Z",
     "start_time": "2024-07-20T20:30:28.483023Z"
    }
   },
   "outputs": [],
   "source": [
    "from embedding_search_benchmarking import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d9568d-0782-4a8e-96c8-d18571a83a40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T20:30:32.513338Z",
     "start_time": "2024-07-20T20:30:31.550281Z"
    }
   },
   "outputs": [],
   "source": [
    "from leeq.utils.ai.code_indexer import build_leeq_code_ltm\n",
    "from leeq.utils.ai.staging.stage_execution import get_codegen_wm, CodegenModel\n",
    "from leeq.utils.ai.variable_table import VariableTable\n",
    "\n",
    "from mllm.config import default_models\n",
    "default_models[\"normal\"] = \"gpt-4o-mini\"\n",
    "default_models[\"expensive\"] = \"gpt-4o\"\n",
    "default_models[\"normal\"] = \"replicate/meta/meta-llama-3-70b-instruct\"\n",
    "default_models[\"expensive\"] = \"replicate/meta/meta-llama-3-70b-instruct\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13157c36-6cac-44c6-8800-b51734b9e447",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T20:31:22.637718Z",
     "start_time": "2024-07-20T20:30:32.525878Z"
    }
   },
   "outputs": [],
   "source": [
    "results = benchmark_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75b45cd-b71b-45a7-9aa2-5e0919577d71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T20:31:22.639378Z",
     "start_time": "2024-07-20T20:31:22.639072Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('embedding_search_benchmark.pkl','wb') as f:\n",
    "    pickle.dump(results,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936f4f2d-7c3e-48c9-9269-12899c6da8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,vs in results.items():\n",
    "    success_list = np.asarray([v[1] for v in vs]).astype(float)\n",
    "    success_rate = success_list.mean()\n",
    "    print(k,success_rate)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
