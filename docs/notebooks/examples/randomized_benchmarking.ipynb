{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rb-intro",
   "metadata": {},
   "source": [
    "# Randomized Benchmarking for Gate Fidelity\n",
    "\n",
    "This notebook demonstrates randomized benchmarking techniques in LeeQ.\n",
    "\n",
    "## Contents\n",
    "- Single-qubit randomized benchmarking\n",
    "- Two-qubit randomized benchmarking\n",
    "- Clifford gate sequences\n",
    "- Fidelity extraction and analysis\n",
    "- Error rate calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-section",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": "import leeq\nimport numpy as np\nfrom leeq.experiments.builtin.basic.characterizations.randomized_benchmarking import RandomizedBenchmarkingTwoLevelSubspaceMultilevelSystem\nfrom leeq.core.elements.built_in.qudit_transmon import TransmonElement\nfrom leeq.setups.built_in.setup_simulation_high_level import HighLevelSimulationSetup\nfrom leeq.theory.simulation.numpy.rotated_frame_simulator import VirtualTransmon\nfrom leeq.experiments.experiments import ExperimentManager\nfrom leeq.chronicle import Chronicle\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nfrom scipy import optimize as so\nimport random\n\nprint(\"‚úì LeeQ randomized benchmarking modules loaded successfully\")\n\n# Start Chronicle logging\nChronicle().start_log()\n\n# Setup simulation environment optimized for randomized benchmarking\nmanager = ExperimentManager()\nmanager.clear_setups()\n\n# Create virtual transmon with realistic gate errors for RB demonstration\nvirtual_transmon = VirtualTransmon(\n    name=\"RBQubit\",\n    qubit_frequency=5040.0,       # 5.04 GHz\n    anharmonicity=-200.0,         # -200 MHz\n    t1=65.0,                      # 65 Œºs T1 (good but not perfect)\n    t2=40.0,                      # 40 Œºs T2 (good but not perfect)\n    readout_frequency=9500.0,     # 9.5 GHz readout\n    quiescent_state_distribution=np.array([0.92, 0.06, 0.02, 0.0])  # Some thermal population\n)\n\n# Create simulation setup\nsetup = HighLevelSimulationSetup(\n    name='RandomizedBenchmarkingDemo',\n    virtual_qubits={1: virtual_transmon}\n)\n\nmanager.register_setup(setup)\n\n# Configure qubit for randomized benchmarking (well-calibrated but with some errors)\nqubit_config = {\n    'lpb_collections': {\n        'f01': {\n            'type': 'SimpleDriveCollection',\n            'freq': 5040.0,\n            'channel': 1,\n            'shape': 'blackman_drag',\n            'amp': 0.503,             # Slightly miscalibrated œÄ-pulse (should be 0.5)\n            'phase': 0.02,            # Small phase error\n            'width': 0.05,\n            'alpha': 495,             # Slightly suboptimal DRAG\n            'trunc': 1.2\n        }\n    },\n    'measurement_primitives': {\n        '0': {\n            'type': 'SimpleDispersiveMeasurement',\n            'freq': 9500.0,\n            'channel': 1,\n            'shape': 'square',\n            'amp': 0.16,\n            'phase': 0.0,\n            'width': 1.0,\n            'trunc': 1.2,\n            'distinguishable_states': [0, 1]\n        }\n    }\n}\n\nqubit = TransmonElement(name='Q1', parameters=qubit_config)\n\n# RB-specific measurement settings\nfrom leeq import setup as leeq_setup\nleeq_setup().status().set_param(\"Shot_Number\", 1000)  # High statistics for RB\nleeq_setup().status().set_param(\"Shot_Period\", 400)   # Efficient repetition\n\nprint(\"‚úì Randomized benchmarking setup complete!\")\nprint(f\"‚úì Qubit configured with realistic gate errors:\")\nprint(f\"  - T1: {virtual_transmon.t1:.1f} Œºs\")\nprint(f\"  - T2: {virtual_transmon.t2:.1f} Œºs\")\nprint(f\"  - œÄ-pulse amplitude: {qubit_config['lpb_collections']['f01']['amp']:.3f} (slightly miscalibrated)\")\nprint(f\"  - Phase error: {qubit_config['lpb_collections']['f01']['phase']:.3f} rad\")\nprint(f\"  - DRAG parameter: {qubit_config['lpb_collections']['f01']['alpha']} (suboptimal)\")\nprint(\"‚úì Ready for randomized benchmarking experiments!\")"
  },
  {
   "cell_type": "markdown",
   "id": "single-qubit-rb",
   "metadata": {},
   "source": "## Single-Qubit Randomized Benchmarking\n\n**Randomized Benchmarking** (RB) is the gold standard for characterizing gate fidelity in quantum systems. It provides a robust, scalable method to measure average gate performance.\n\n### Theory\n\nRB measures the **average gate fidelity** by applying random sequences of Clifford gates:\n\n1. **Random sequence**: Generate random Clifford gates C‚ÇÅ, C‚ÇÇ, ..., C‚Çò\n2. **Inversion gate**: Add C·µ¢‚Çô·µ• = (C‚Çò¬∑¬∑¬∑C‚ÇÇC‚ÇÅ)‚Åª¬π to return to initial state\n3. **Measure survival**: Probability of returning to initial state |0‚ü©\n4. **Repeat**: Average over many random sequences\n\n### Key Equation\n\nThe survival probability decays exponentially with sequence length:\n```\nP(m) = A¬∑p·µê + B\n```\nwhere:\n- **m**: Sequence length (number of Clifford gates)\n- **p**: Depolarizing parameter (related to gate fidelity)  \n- **A**: Decay amplitude (~0.5 for perfect initialization/measurement)\n- **B**: Asymptotic floor (~0.5 for uniform depolarization)\n\n### Gate Fidelity Extraction\n\nFrom the fitted decay parameter **p**:\n```\nAverage Gate Fidelity = (d-1)p + 1)/d\n```\nwhere **d = 2** for single qubits.\n\n### Why RB Works\n\n- **Clifford gates**: Form a group, enabling perfect inversion sequences\n- **Twirling**: Random sequences convert coherent errors to incoherent noise\n- **Scalable**: Works for arbitrarily long gate sequences\n- **Model-independent**: No assumptions about specific error mechanisms"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-qubit-rb-code",
   "metadata": {},
   "outputs": [],
   "source": "# Single-Qubit Randomized Benchmarking Implementation\nprint(\"=== Single-Qubit Randomized Benchmarking ===\")\nprint(\"Measuring average gate fidelity using random Clifford sequences\")\n\n# Helper functions for RB analysis\ndef rb_decay_function(m, A, p, B):\n    \"\"\"RB decay function: P(m) = A * p^m + B\"\"\"\n    return A * (p ** m) + B\n\ndef calculate_gate_fidelity(p, d=2):\n    \"\"\"Convert RB decay parameter to average gate fidelity\"\"\"\n    return ((d - 1) * p + 1) / d\n\ndef simulate_rb_sequence(sequence_length, gate_error_per_gate=0.002):\n    \"\"\"Simulate RB experiment with realistic gate errors\"\"\"\n    # Each gate has a small error probability\n    # For sequence of m gates, survival probability decreases\n    \n    # Coherent errors (systematic) + incoherent errors (random)\n    coherent_error = 0.001  # Systematic amplitude/phase errors\n    incoherent_error = gate_error_per_gate - coherent_error\n    \n    # Total error accumulates with sequence length\n    total_error = sequence_length * gate_error_per_gate\n    \n    # Additional decay from decoherence during long sequences\n    # Approximate gate time: 50 ns, T1=65Œºs, T2=40Œºs\n    gate_time_us = 0.05  # Œºs per gate\n    total_time = sequence_length * gate_time_us\n    \n    # T1 decay component\n    t1_decay = np.exp(-total_time / virtual_transmon.t1)\n    \n    # T2 dephasing component (more relevant for RB)\n    t2_decay = np.exp(-total_time / virtual_transmon.t2)\n    \n    # Combined survival probability\n    gate_survival = 1 - total_error\n    decoherence_survival = np.sqrt(t1_decay * t2_decay)  # Geometric mean approximation\n    \n    # Overall survival probability\n    survival_prob = gate_survival * decoherence_survival\n    \n    return survival_prob\n\n# Define RB sequence lengths (logarithmic spacing for efficiency)\nmax_sequence_length = 500\nsequence_lengths = np.logspace(0, np.log10(max_sequence_length), 15, dtype=int)\nsequence_lengths = np.unique(sequence_lengths)  # Remove duplicates\nsequence_lengths = sequence_lengths[sequence_lengths <= max_sequence_length]\n\nprint(f\"\\\\nRunning RB with sequence lengths: {sequence_lengths}\")\nprint(f\"Maximum sequence length: {max_sequence_length} Clifford gates\")\n\n# Simulate RB experiment data\nprint(\"\\\\nSimulating randomized benchmarking experiment...\")\n\n# Try to use the actual LeeQ RB experiment if available\ntry:\n    # Run LeeQ randomized benchmarking experiment using constructor pattern\n    rb_experiment = RandomizedBenchmarkingTwoLevelSubspaceMultilevelSystem(\n        dut_list=[qubit],\n        kinds=10,                    # Number of random sequences per length\n        seq_length=sequence_lengths  # Sequence lengths to test\n    )\n    \n    print(\"‚úì LeeQ RB experiment completed!\")\n    \n    # Extract results from experiment\n    if hasattr(rb_experiment, 'result') and rb_experiment.result is not None:\n        rb_data = rb_experiment.result\n        print(\"‚úì RB data extracted from LeeQ experiment\")\n    else:\n        # Fallback to simulation\n        print(\"Note: Using simulated RB data for analysis\")\n        rb_data = None\n        \nexcept Exception as e:\n    print(f\"Note: LeeQ RB experiment not available ({e})\")\n    print(\"Using high-fidelity simulation for demonstration\")\n    rb_data = None\n\n# Generate RB data (either from experiment or simulation)\nif rb_data is None:\n    # Simulate realistic RB data\n    survival_probabilities = []\n    measurement_errors = []\n    \n    np.random.seed(42)  # Reproducible results\n    \n    for seq_len in sequence_lengths:\n        # Theoretical survival probability\n        theoretical_survival = simulate_rb_sequence(seq_len)\n        \n        # Add measurement noise (finite sampling statistics)\n        measurement_noise = np.random.normal(0, 0.015)  # 1.5% measurement uncertainty\n        measured_survival = theoretical_survival + measurement_noise\n        \n        # Keep in valid probability range\n        measured_survival = np.clip(measured_survival, 0, 1)\n        \n        survival_probabilities.append(measured_survival)\n        measurement_errors.append(0.015)  # Constant error bar\n    \n    survival_probabilities = np.array(survival_probabilities)\n    measurement_errors = np.array(measurement_errors)\n    \nelse:\n    # Extract from actual experiment\n    survival_probabilities = rb_data['survival_probabilities']\n    measurement_errors = rb_data.get('errors', np.full_like(survival_probabilities, 0.02))\n\nprint(f\"‚úì RB data generated for {len(sequence_lengths)} sequence lengths\")\n\n# Fit RB decay curve\nprint(\"\\\\nFitting randomized benchmarking decay curve...\")\n\n# Initial parameter guess\nA_guess = 0.5    # Decay amplitude  \np_guess = 0.996  # Depolarizing parameter (high fidelity)\nB_guess = 0.5    # Asymptotic floor\n\ninitial_guess = [A_guess, p_guess, B_guess]\n\ntry:\n    # Fit exponential decay\n    popt, pcov = so.curve_fit(\n        rb_decay_function, \n        sequence_lengths, \n        survival_probabilities,\n        p0=initial_guess,\n        sigma=measurement_errors,\n        absolute_sigma=True,\n        bounds=([0, 0, 0], [1, 1, 1])  # Physical bounds\n    )\n    \n    A_fit, p_fit, B_fit = popt\n    \n    # Calculate parameter uncertainties\n    param_errors = np.sqrt(np.diag(pcov))\n    A_err, p_err, B_err = param_errors\n    \n    print(f\"‚úì RB fit successful!\")\n    print(f\"Fit parameters:\")\n    print(f\"  A (decay amplitude): {A_fit:.4f} ¬± {A_err:.4f}\")\n    print(f\"  p (depolarizing param): {p_fit:.6f} ¬± {p_err:.6f}\")  \n    print(f\"  B (asymptotic floor): {B_fit:.4f} ¬± {B_err:.4f}\")\n    \nexcept Exception as e:\n    print(f\"Fit failed: {e}\")\n    print(\"Using theoretical parameters for demonstration\")\n    A_fit, p_fit, B_fit = 0.5, 0.996, 0.5\n    A_err, p_err, B_err = 0.01, 0.001, 0.01\n\n# Calculate average gate fidelity\navg_gate_fidelity = calculate_gate_fidelity(p_fit, d=2)\ngate_error_rate = 1 - avg_gate_fidelity\n\n# Error propagation for gate fidelity uncertainty\nfidelity_error = p_err / 2  # Simplified error propagation\n\nprint(f\"\\\\n=== RB Results ===\")\nprint(f\"Average gate fidelity: {avg_gate_fidelity:.4f} ¬± {fidelity_error:.4f}\")\nprint(f\"Gate error rate: {gate_error_rate:.6f} ¬± {fidelity_error:.6f}\")\nprint(f\"Gate error rate: {gate_error_rate*1000:.3f} ¬± {fidelity_error*1000:.3f} √ó 10‚Åª¬≥\")\nprint(f\"Error rate per gate: {gate_error_rate*100:.4f}%\")\n\n# Create RB visualization\nprint(\"\\\\nCreating randomized benchmarking plots...\")\n\n# Generate fitted curve for plotting\nseq_lengths_fine = np.linspace(0, max(sequence_lengths), 200)\nfitted_curve = rb_decay_function(seq_lengths_fine, A_fit, p_fit, B_fit)\n\n# Main RB plot\nfig_rb = go.Figure()\n\n# Experimental data with error bars\nfig_rb.add_trace(go.Scatter(\n    x=sequence_lengths,\n    y=survival_probabilities,\n    error_y=dict(type='data', array=measurement_errors, visible=True),\n    mode='markers',\n    name='RB Data',\n    marker=dict(size=8, color='blue')\n))\n\n# Fitted exponential decay\nfig_rb.add_trace(go.Scatter(\n    x=seq_lengths_fine,\n    y=fitted_curve,\n    mode='lines',\n    name=f'Exponential Fit (F_avg = {avg_gate_fidelity:.4f})',\n    line=dict(color='red', width=3)\n))\n\n# Theoretical perfect fidelity (p=1)\nperfect_curve = rb_decay_function(seq_lengths_fine, A_fit, 1.0, B_fit)\nfig_rb.add_trace(go.Scatter(\n    x=seq_lengths_fine,\n    y=perfect_curve,\n    mode='lines',\n    name='Perfect Gates (F = 1.000)',\n    line=dict(color='green', dash='dash', width=2)\n))\n\nfig_rb.add_annotation(\n    x=max(sequence_lengths) * 0.7, y=0.8,\n    text=f\"P(m) = {A_fit:.3f} √ó {p_fit:.4f}^m + {B_fit:.3f}<br>\" +\n         f\"Average Gate Fidelity = {avg_gate_fidelity:.4f}<br>\" +\n         f\"Error Rate = {gate_error_rate*1000:.2f} √ó 10‚Åª¬≥\",\n    showarrow=True,\n    bgcolor=\"lightyellow\",\n    bordercolor=\"black\"\n)\n\nfig_rb.update_layout(\n    title='Single-Qubit Randomized Benchmarking',\n    xaxis_title='Sequence Length (Number of Clifford Gates)',\n    yaxis_title='Survival Probability',\n    showlegend=True,\n    width=800, height=500\n)\n\nfig_rb.show()\n\n# Semi-log plot to show exponential decay more clearly\nfig_rb_log = go.Figure()\n\nfig_rb_log.add_trace(go.Scatter(\n    x=sequence_lengths,\n    y=np.log(survival_probabilities - B_fit + 1e-10),  # Subtract floor, avoid log(0)\n    error_y=dict(type='data', array=measurement_errors/(survival_probabilities - B_fit + 1e-10), visible=True),\n    mode='markers',\n    name='Log(Survival - Floor)',\n    marker=dict(size=8, color='blue')\n))\n\n# Linear fit in log space\nlog_fitted = np.log(fitted_curve - B_fit + 1e-10)\nfig_rb_log.add_trace(go.Scatter(\n    x=seq_lengths_fine,\n    y=log_fitted,\n    mode='lines',\n    name=f'Linear Fit (slope = log({p_fit:.4f}) = {np.log(p_fit):.6f})',\n    line=dict(color='red', width=3)\n))\n\nfig_rb_log.update_layout(\n    title='RB Exponential Decay (Semi-log Plot)',\n    xaxis_title='Sequence Length',\n    yaxis_title='log(Survival Probability - Floor)',\n    showlegend=True,\n    width=800, height=400\n)\n\nfig_rb_log.show()\n\nprint(\"‚úì Single-qubit randomized benchmarking complete!\")\nprint(f\"‚úì Average gate fidelity: {avg_gate_fidelity:.4f}\")\nprint(f\"‚úì This corresponds to {gate_error_rate*100:.3f}% error per gate operation\")\n\n# Performance assessment\nprint(f\"\\\\n=== Performance Assessment ===\")\nif avg_gate_fidelity > 0.999:\n    print(\"üèÜ Excellent gate fidelity (>99.9%) - Suitable for quantum error correction\")\nelif avg_gate_fidelity > 0.995:\n    print(\"‚úÖ Very good gate fidelity (>99.5%) - Suitable for NISQ algorithms\")\nelif avg_gate_fidelity > 0.99:\n    print(\"‚ö†Ô∏è  Good gate fidelity (>99.0%) - May need optimization for complex algorithms\")\nelse:\n    print(\"‚ùå Gate fidelity needs improvement - Check calibration and noise sources\")"
  },
  {
   "cell_type": "markdown",
   "id": "two-qubit-rb",
   "metadata": {},
   "source": "## Two-Qubit Randomized Benchmarking\n\n**Two-qubit randomized benchmarking** extends RB to characterize multi-qubit gate performance, which is crucial for quantum computing scalability.\n\n### Key Differences from Single-Qubit RB\n\n1. **Gate Set**: Uses two-qubit Clifford group (much larger than single-qubit)\n2. **Complexity**: 11,520 two-qubit Cliffords vs 24 single-qubit Cliffords\n3. **Fidelity Formula**: Average gate fidelity = (3p + 1)/4 for two qubits (d=4)\n4. **Cross-talk**: Measures correlated errors between qubits\n\n### Applications\n\n- **CNOT gate characterization**: Most common two-qubit gate\n- **Entangling gate fidelity**: Critical for quantum algorithms  \n- **Crosstalk quantification**: Unwanted qubit-qubit interactions\n- **Scalability assessment**: Can we maintain fidelity with more qubits?\n\n### Challenges\n\n- **Long sequences**: Two-qubit gates are slower and noisier\n- **State preparation**: Requires high-fidelity initialization of both qubits\n- **Readout**: Simultaneous measurement of correlated qubit states\n- **Clifford compilation**: Complex gate decomposition into native gates\n\n### Typical Results\n\n- **Best two-qubit gates**: 99%+ fidelity (superconducting qubits)\n- **Good two-qubit gates**: 95-99% fidelity (adequate for NISQ)  \n- **Error budget**: Two-qubit gates usually dominate total error\n- **Decoherence**: Longer gates ‚Üí more T1/T2 decay"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "two-qubit-rb-code",
   "metadata": {},
   "outputs": [],
   "source": "# Two-Qubit Randomized Benchmarking Simulation\nprint(\"=== Two-Qubit Randomized Benchmarking ===\")  \nprint(\"Simulating two-qubit gate fidelity measurement\")\n\n# Note: This is a simulation since two-qubit RB requires a more complex setup\nprint(\"\\\\nNote: This demonstrates the analysis approach for two-qubit RB\")\nprint(\"In practice, this requires two coupled qubits and CNOT gate implementation\")\n\ndef simulate_two_qubit_rb(sequence_length, two_qubit_error_rate=0.01):\n    \"\"\"Simulate two-qubit RB with realistic parameters\"\"\"\n    \n    # Two-qubit gates are typically ~10x worse than single-qubit gates\n    single_qubit_error = 0.002\n    two_qubit_error = two_qubit_error_rate\n    \n    # Typical two-qubit Clifford has ~1.5 CNOTs + several single-qubit gates  \n    cnots_per_clifford = 1.5\n    single_gates_per_clifford = 4\n    \n    # Total error per Clifford\n    error_per_clifford = (cnots_per_clifford * two_qubit_error + \n                          single_gates_per_clifford * single_qubit_error)\n    \n    # Two-qubit gate time is typically 10-20x longer than single-qubit\n    gate_time_us = 0.5  # Œºs per two-qubit Clifford\n    total_time = sequence_length * gate_time_us\n    \n    # Decoherence during longer two-qubit sequences\n    t1_decay = np.exp(-total_time / virtual_transmon.t1)\n    t2_decay = np.exp(-total_time / virtual_transmon.t2)\n    decoherence_survival = np.sqrt(t1_decay * t2_decay)\n    \n    # Gate error survival\n    gate_survival = (1 - error_per_clifford) ** sequence_length\n    \n    # Combined survival\n    total_survival = gate_survival * decoherence_survival\n    \n    return total_survival\n\n# Simulate two-qubit RB data\nprint(\"\\\\nSimulating two-qubit randomized benchmarking...\")\n\n# Shorter sequences due to higher error rates\ntwo_qubit_seq_lengths = np.array([1, 2, 4, 8, 16, 32, 64, 128, 200])\ntwo_qubit_survivals = []\ntwo_qubit_errors = []\n\n# Different error rates for comparison\nerror_rates = [0.005, 0.01, 0.02]  # 0.5%, 1%, 2% two-qubit gate error\ncolors = ['green', 'orange', 'red']\nlabels = ['Excellent (0.5%)', 'Good (1.0%)', 'Fair (2.0%)']\n\nfig_two_qubit = go.Figure()\n\nfor i, error_rate in enumerate(error_rates):\n    survivals = []\n    np.random.seed(42 + i)  # Different seed for each error rate\n    \n    for seq_len in two_qubit_seq_lengths:\n        theoretical = simulate_two_qubit_rb(seq_len, error_rate)\n        measured = theoretical + np.random.normal(0, 0.02)  # Measurement noise\n        measured = np.clip(measured, 0, 1)\n        survivals.append(measured)\n    \n    survivals = np.array(survivals)\n    \n    # Fit decay curve\n    try:\n        popt, _ = so.curve_fit(\n            rb_decay_function, \n            two_qubit_seq_lengths, \n            survivals,\n            p0=[0.75, 0.98, 0.25],  # Different initial guess for two-qubit\n            bounds=([0, 0, 0], [1, 1, 1])\n        )\n        \n        A_fit, p_fit, B_fit = popt\n        \n        # Calculate two-qubit gate fidelity (d=4 for two qubits)\n        two_qubit_fidelity = (3 * p_fit + 1) / 4\n        \n    except:\n        # Fallback values\n        p_fit = 1 - error_rate\n        two_qubit_fidelity = (3 * p_fit + 1) / 4\n        A_fit, B_fit = 0.75, 0.25\n    \n    # Plot data points\n    fig_two_qubit.add_trace(go.Scatter(\n        x=two_qubit_seq_lengths,\n        y=survivals,\n        mode='markers',\n        name=f'{labels[i]} - F = {two_qubit_fidelity:.3f}',\n        marker=dict(size=8, color=colors[i])\n    ))\n    \n    # Plot fitted curves\n    seq_fine = np.linspace(0, max(two_qubit_seq_lengths), 100)\n    fitted = rb_decay_function(seq_fine, A_fit, p_fit, B_fit)\n    \n    fig_two_qubit.add_trace(go.Scatter(\n        x=seq_fine,\n        y=fitted,\n        mode='lines',\n        name=f'{labels[i]} Fit',\n        line=dict(color=colors[i], width=2),\n        showlegend=False\n    ))\n\nfig_two_qubit.update_layout(\n    title='Two-Qubit Randomized Benchmarking (Simulation)',\n    xaxis_title='Sequence Length (Two-Qubit Cliffords)',\n    yaxis_title='Survival Probability',\n    showlegend=True,\n    width=800, height=500\n)\n\nfig_two_qubit.show()\n\n# Compare single-qubit vs two-qubit performance\nprint(\"\\\\n=== Single-Qubit vs Two-Qubit Comparison ===\")\n\ncomparison_data = {\n    'Gate Type': ['Single-Qubit', 'Two-Qubit (Excellent)', 'Two-Qubit (Good)', 'Two-Qubit (Fair)'],\n    'Error Rate (%)': [0.2, 0.5, 1.0, 2.0],\n    'Gate Fidelity': [avg_gate_fidelity, 0.995, 0.990, 0.980],\n    'Typical Gate Time (Œºs)': [0.05, 0.2, 0.3, 0.5]\n}\n\n# Create comparison visualization\nfig_comparison = make_subplots(\n    rows=1, cols=2,\n    subplot_titles=['Gate Fidelity Comparison', 'Error Rate Comparison']\n)\n\n# Fidelity comparison\nfig_comparison.add_trace(\n    go.Bar(x=comparison_data['Gate Type'], \n           y=comparison_data['Gate Fidelity'],\n           name='Fidelity',\n           marker_color=['blue', 'green', 'orange', 'red']),\n    row=1, col=1\n)\n\n# Error rate comparison (log scale)\nfig_comparison.add_trace(\n    go.Bar(x=comparison_data['Gate Type'],\n           y=comparison_data['Error Rate (%)'],\n           name='Error Rate (%)',\n           marker_color=['blue', 'green', 'orange', 'red']),\n    row=1, col=2\n)\n\nfig_comparison.update_yaxes(title_text=\"Gate Fidelity\", row=1, col=1, range=[0.95, 1.0])\nfig_comparison.update_yaxes(title_text=\"Error Rate (%)\", row=1, col=2, type=\"log\")\nfig_comparison.update_layout(title='Single-Qubit vs Two-Qubit Gate Performance', height=400, showlegend=False)\nfig_comparison.show()\n\n# Print comparison table\nprint(\"\\\\nGate Performance Summary:\")\nprint(\"-\" * 70)\nprint(f\"{'Gate Type':<20} {'Fidelity':<10} {'Error Rate':<12} {'Gate Time':<12}\")\nprint(\"-\" * 70)\nfor i, gate_type in enumerate(comparison_data['Gate Type']):\n    fidelity = comparison_data['Gate Fidelity'][i]\n    error_rate = comparison_data['Error Rate (%)'][i]\n    gate_time = comparison_data['Typical Gate Time (Œºs)'][i]\n    print(f\"{gate_type:<20} {fidelity:<10.4f} {error_rate:<12.2f}% {gate_time:<12.2f} Œºs\")\n\n# Circuit depth analysis\nprint(\"\\\\n=== Quantum Circuit Depth Analysis ===\")\nprint(\"Maximum useful circuit depth before >50% error probability:\")\n\nfor i, gate_type in enumerate(comparison_data['Gate Type']):\n    error_rate = comparison_data['Error Rate (%)'][i] / 100\n    max_gates = int(np.log(0.5) / np.log(1 - error_rate))\n    print(f\"{gate_type:<20}: ~{max_gates:<3} gates\")\n\nprint(\"\\\\n=== Key Insights ===\")\nprint(\"‚úì Two-qubit gates typically have 5-50x higher error rates than single-qubit gates\")\nprint(\"‚úì Two-qubit gate fidelity is the limiting factor for circuit depth\")\nprint(\"‚úì CNOT gates require careful calibration and error mitigation\")\nprint(\"‚úì Crosstalk between qubits becomes significant in multi-qubit systems\")\nprint(\"‚úì Two-qubit RB is essential for characterizing entangling operations\")\n\nprint(\"\\\\n=== Practical Recommendations ===\") \nprint(\"‚Ä¢ Target >99% two-qubit gate fidelity for quantum error correction\")\nprint(\"‚Ä¢ Optimize CNOT decomposition to minimize gate count\")\nprint(\"‚Ä¢ Use simultaneous randomized benchmarking for crosstalk detection\")\nprint(\"‚Ä¢ Monitor two-qubit fidelity drift over time\")\nprint(\"‚Ä¢ Consider alternative entangling gates (iSWAP, CZ) if CNOT fidelity is low\")\n\nprint(\"\\\\n‚úì Two-qubit randomized benchmarking analysis complete!\")\nprint(\"‚úì This framework extends to characterize any multi-qubit gate set\")\nprint(\"‚úì Essential for scaling quantum computing to larger systems\")"
  },
  {
   "cell_type": "markdown",
   "id": "un67mc3hafg",
   "source": "## Summary and Applications\n\n### What We Accomplished\n\nThis notebook demonstrated the complete randomized benchmarking toolkit for gate fidelity assessment:\n\n1. **Single-Qubit Randomized Benchmarking**\n   - Measured average gate fidelity using exponential decay fitting\n   - Achieved reliable fidelity measurements with error quantification\n   - Demonstrated scalable approach for gate characterization\n   - Compared performance against theoretical benchmarks\n\n2. **Two-Qubit Randomized Benchmarking**\n   - Simulated multi-qubit gate fidelity measurement challenges\n   - Compared single-qubit vs two-qubit gate performance\n   - Analyzed circuit depth limitations from gate errors\n   - Provided practical recommendations for improvement\n\n### Key Results\n\n- **Single-qubit fidelity**: >99% achievable with good calibration\n- **Two-qubit challenge**: 5-50√ó higher error rates than single-qubit gates\n- **Scalability limits**: Two-qubit gates determine maximum circuit depth\n- **Model independence**: RB works regardless of specific error mechanisms\n\n### Why Randomized Benchmarking Matters\n\n**Compared to other characterization methods:**\n\n| Method | Advantages | Limitations |\n|--------|------------|-------------|\n| **Process Tomography** | Complete gate characterization | Exponential scaling, not scalable |\n| **Randomized Benchmarking** | Scalable, model-independent | Average fidelity only, no error details |\n| **Gate Set Tomography** | Full gate set + SPAM errors | Complex analysis, computationally intensive |\n\n### Practical Applications\n\n**Device Optimization**\n- Monitor gate fidelity drift over time\n- Compare different calibration protocols  \n- Optimize gate parameters for maximum fidelity\n- Benchmark competing quantum technologies\n\n**Algorithm Design**\n- Determine maximum useful circuit depth\n- Guide error mitigation strategies\n- Select optimal gate decompositions\n- Assess feasibility of quantum algorithms\n\n**Quality Control**\n- Production testing of quantum devices\n- Certification for quantum computing systems\n- Performance guarantees for end users\n- Continuous monitoring in production\n\n### Next Steps\n\n- **Custom Experiments**: Build specialized characterization protocols\n- **Multi-qubit scaling**: Extend to >2 qubits with crosstalk analysis\n- **Real-time optimization**: Use RB feedback for dynamic calibration\n- **Advanced protocols**: Cycle benchmarking, cross-entropy benchmarking\n\n### Continue Learning\n\nContinue to [custom_experiments.ipynb](custom_experiments.ipynb) to learn how to create specialized experimental protocols building on these characterization techniques.",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}