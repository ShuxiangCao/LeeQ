{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ai-integration-intro",
   "metadata": {},
   "source": [
    "# 05 - AI-Assisted Experiment Generation\n",
    "\n",
    "This notebook demonstrates LeeQ's unique AI integration capabilities for automated experiment generation and optimization.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand AI-assisted experiment design\n",
    "- Learn about automated parameter optimization\n",
    "- Practice with intelligent calibration workflows\n",
    "- Explore LLM integration for experiment planning\n",
    "\n",
    "## Prerequisites\n",
    "- Complete [04_calibration.ipynb](04_calibration.ipynb)\n",
    "- Understanding of machine learning concepts (helpful but not required)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-section",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import-modules",
   "metadata": {},
   "outputs": [],
   "source": "import leeq\nimport numpy as np\nfrom leeq.utils.ai.experiment_generation import generate_experiment, break_down_description\nfrom leeq.utils.ai.translation_agent import init_leeq_translation_agents\nfrom leeq.core.elements.built_in.qudit_transmon import TransmonElement\nfrom leeq.experiments.builtin.basic.calibrations import (\n    NormalisedRabi, SimpleRamseyMultilevel\n)\nfrom leeq.experiments.builtin.basic.characterizations import SimpleT1, SpinEchoMultiLevel\nfrom leeq.chronicle import Chronicle, log_and_record\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n# Import shared utilities\nfrom docs.notebooks.shared.setup_templates import initialize_notebook_environment\nfrom docs.notebooks.shared.experiment_helpers import (\n    run_basic_calibration_sequence, \n    run_coherence_characterization,\n    analyze_calibration_results,\n    plot_rabi_oscillation,\n    plot_coherence_measurements\n)\n\n# Import k_agents decorators for AI inspection\nfrom k_agents.inspection.decorator import text_inspection, visual_inspection\n\n# Setup AI environment\ntry:\n    # Initialize LeeQ translation agents for AI-assisted analysis\n    init_leeq_translation_agents()\n    print(\"✓ AI translation agents initialized successfully\")\nexcept Exception as e:\n    print(f\"⚠ AI agents not available: {e}\")\n    print(\"Continuing with mock AI functionality for demonstration\")\n\nprint(\"Environment setup complete!\")"
  },
  {
   "cell_type": "markdown",
   "id": "ai-experiment-design",
   "metadata": {},
   "source": "## AI-Assisted Experiment Design\n\nLeeQ's AI integration allows you to design experiments using natural language descriptions. \nThe AI system can parse your requirements and generate complete experiment code automatically.\n\n### Key AI Features:\n- **Natural Language Processing**: Describe experiments in plain English\n- **Automated Code Generation**: Generate complete LeeQ experiment classes\n- **Intelligent Parameter Suggestions**: AI recommends optimal experimental parameters\n- **Result Analysis**: Automated interpretation of experimental data"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ai-experiment-code",
   "metadata": {},
   "outputs": [],
   "source": "# Setup simulation environment for AI experiments\nmanager, duts_dict = initialize_notebook_environment(single_qubit=True)\ndut = duts_dict['Q1']\n\n# Example 1: AI-Assisted Experiment Description\nexperiment_description = \"\"\"\nI want to measure the T1 relaxation time of my qubit. \nThe experiment should:\n1. Prepare the qubit in the excited state with a π pulse\n2. Wait for varying delay times from 0 to 300 microseconds\n3. Measure the qubit state to see the population decay\n4. Fit the decay to extract T1 time constant\n5. Create a visualization showing the exponential decay curve\n\"\"\"\n\nprint(\"🤖 AI Experiment Description:\")\nprint(experiment_description)\nprint()\n\n# Use real LeeQ AI experiment breakdown if available\ntry:\n    # Break down the experiment description using real AI\n    print(\"🤖 AI Analysis of Experiment Description:\")\n    ai_breakdown = break_down_description(experiment_description)\n    for key, value in ai_breakdown.items():\n        print(f\"• {key.title()}: {value}\")\n        \n    print(\"\\n✓ AI successfully parsed experiment requirements!\")\n    \nexcept Exception as e:\n    print(f\"⚠ AI breakdown not available: {e}\")\n    print(\"Using mock AI breakdown for demonstration:\")\n    \n    # Mock AI experiment breakdown for demonstration\n    ai_breakdown = {\n        'summary': 'T1 relaxation time measurement experiment',\n        'pulse_sequences': 'Apply π pulse, variable delay, measure qubit state', \n        'data_analysis': 'Exponential decay fitting to extract T1',\n        'data_visualization': 'Plot population vs time with fitted curve'\n    }\n    \n    for key, value in ai_breakdown.items():\n        print(f\"• {key.title()}: {value}\")\n\n# Demonstrate real experiment generation if AI is available\nprint(\"\\n🔬 Generating AI Experiment (if available):\")\ntry:\n    # Try to generate a real experiment using AI\n    ai_generated_code = generate_experiment(experiment_description, display_progress=False)\n    print(\"✓ AI successfully generated experiment code!\")\n    print(\"Generated code preview:\")\n    print(ai_generated_code[:200] + \"...\" if len(ai_generated_code) > 200 else ai_generated_code)\nexcept Exception as e:\n    print(f\"⚠ AI experiment generation not available: {e}\")\n    print(\"Continuing with builtin experiments for demonstration\")"
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-calibration",
   "metadata": {},
   "source": "## Intelligent Calibration Workflows\n\nThe AI system can analyze calibration results and suggest optimizations for better performance.\nThis includes parameter refinement, sequence optimization, and adaptive calibration strategies.\n\n### AI Calibration Features:\n- **Parameter Optimization**: AI suggests optimal parameter ranges\n- **Adaptive Sequences**: Dynamic adjustment based on intermediate results\n- **Error Analysis**: Intelligent identification of calibration issues\n- **Performance Metrics**: AI-driven quality assessment"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-calibration-code",
   "metadata": {},
   "outputs": [],
   "source": "# Run standard calibration sequence\nprint(\"🔬 Running AI-Assisted Calibration Sequence...\")\ncalibration_results = run_basic_calibration_sequence(dut, update_params=False)\n\n# AI analysis of calibration results\nprint(\"\\n🤖 AI Analysis of Calibration Results:\")\ncalib_summary = analyze_calibration_results(calibration_results)\n\n# Mock AI parameter suggestions based on results\ndef ai_parameter_suggestions(calib_results):\n    \"\"\"Mock AI parameter optimization suggestions.\"\"\"\n    suggestions = {\n        'pi_amplitude_optimization': {\n            'current': 0.55,\n            'suggested': 0.52,\n            'reason': 'Slight reduction may improve gate fidelity based on Rabi oscillation analysis'\n        },\n        'frequency_calibration': {\n            'current': 'Within tolerance',\n            'suggested': 'Re-calibrate in 24 hours',\n            'reason': 'Frequency drift typical for this timescale'\n        },\n        'coherence_optimization': {\n            'suggestion': 'Increase pulse amplitude slightly',\n            'reason': 'T2 measurements suggest room for improvement'\n        }\n    }\n    return suggestions\n\nai_suggestions = ai_parameter_suggestions(calibration_results)\nprint(\"\\n🎯 AI Parameter Optimization Suggestions:\")\nfor param, details in ai_suggestions.items():\n    print(f\"\\n• {param.replace('_', ' ').title()}:\")\n    for key, value in details.items():\n        print(f\"  - {key.title()}: {value}\")\n\n# Create visualization of calibration results\nif 'rabi' in calibration_results:\n    fig = plot_rabi_oscillation(calibration_results['rabi'], \n                               title=\"AI-Analyzed Rabi Oscillation\")\n    if fig:\n        fig.show()\n\nprint(\"\\n✓ AI-assisted calibration analysis complete!\")"
  },
  {
   "cell_type": "markdown",
   "id": "llm-integration",
   "metadata": {},
   "source": "## LLM Integration for Experiment Planning\n\nLeeQ integrates Large Language Models (LLMs) to assist with experiment planning, \nparameter optimization, and result interpretation. This provides an intelligent \nassistant for quantum experiment workflows.\n\n### LLM Capabilities:\n- **Experiment Planning**: Generate step-by-step experimental procedures\n- **Parameter Selection**: Suggest optimal parameter ranges and values\n- **Result Interpretation**: Automated analysis and explanation of results\n- **Troubleshooting**: AI-powered debugging and optimization suggestions"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "llm-integration-code",
   "metadata": {},
   "outputs": [],
   "source": "# Example: LLM-Assisted Experiment Planning\nprint(\"🤖 LLM-Assisted Experiment Planning Demo\")\nprint(\"=\"*50)\n\n# Mock LLM conversation for experiment planning\ndef mock_llm_conversation(query):\n    \"\"\"Mock LLM responses for demonstration.\"\"\"\n    responses = {\n        \"coherence_measurement\": \"\"\"\n        📋 Recommended Coherence Measurement Protocol:\n        \n        1. **T1 Measurement** (Relaxation):\n           - Use π pulse preparation\n           - Sweep delay time: 0 to 300 μs\n           - Step size: 5 μs for good resolution\n           - Expected T1: ~70 μs for this system\n        \n        2. **T2 Echo Measurement** (Dephasing):\n           - Use π/2 - delay - π - delay - π/2 sequence\n           - Sweep total delay: 0 to 200 μs\n           - Expected T2 echo: ~35 μs\n        \n        3. **Analysis Strategy**:\n           - Fit exponential decay: P(t) = A*exp(-t/T) + C\n           - Check R² > 0.95 for good fit quality\n           - Compare T2 < 2*T1 for consistency check\n        \"\"\",\n        \n        \"parameter_optimization\": \"\"\"\n        🎯 Parameter Optimization Strategy:\n        \n        **Current Performance Analysis:**\n        - Rabi frequency: Good oscillation contrast\n        - Frequency calibration: Stable, minimal drift\n        - Gate fidelity: Estimated >99% based on calibration\n        \n        **Optimization Recommendations:**\n        1. **Pulse Amplitude**: Consider 2-5% reduction for better fidelity\n        2. **DRAG Parameter**: Current value appears optimal\n        3. **Measurement Integration**: Could increase by 10% for better SNR\n        \n        **Next Steps:**\n        - Run process tomography for precise fidelity measurement\n        - Implement randomized benchmarking for gate error quantification\n        \"\"\",\n        \n        \"experiment_troubleshooting\": \"\"\"\n        🔧 Experiment Troubleshooting Assistant:\n        \n        **Common Issues and Solutions:**\n        \n        1. **Poor Rabi Oscillation Contrast:**\n           - Check measurement calibration\n           - Verify pulse amplitude calibration\n           - Consider thermal population effects\n        \n        2. **Frequency Drift During Calibration:**\n           - Re-run resonator spectroscopy\n           - Check environmental stability\n           - Consider shorter calibration sequences\n        \n        3. **Inconsistent T1/T2 Values:**\n           - Verify pulse sequence timing\n           - Check for measurement-induced decay\n           - Validate fitting procedure\n        \"\"\"\n    }\n    return responses.get(query, \"Query not recognized\")\n\n# Demonstrate different LLM assistances\nqueries = [\n    (\"coherence_measurement\", \"How should I design a coherence measurement protocol?\"),\n    (\"parameter_optimization\", \"Can you analyze my calibration results and suggest optimizations?\"),\n    (\"experiment_troubleshooting\", \"I'm having issues with my experiments. Can you help debug?\")\n]\n\nfor query_key, question in queries:\n    print(f\"\\n❓ User Query: {question}\")\n    print(\"🤖 LLM Assistant Response:\")\n    print(mock_llm_conversation(query_key))\n    print(\"-\" * 50)\n\n# Run coherence measurements as suggested by LLM\nprint(\"\\n🔬 Implementing LLM Suggestions - Running Coherence Measurements:\")\ncoherence_results = run_coherence_characterization(dut)\n\n# Create comprehensive visualization\nif coherence_results:\n    coherence_fig = plot_coherence_measurements(coherence_results)\n    if coherence_fig:\n        coherence_fig.show()\n\n# LLM Analysis of Coherence Results\nprint(\"\\n🤖 LLM Analysis of Coherence Results:\")\nif 't1' in coherence_results:\n    print(\"• T1 Measurement: Successfully completed with exponential decay\")\nif 't2_echo' in coherence_results:\n    print(\"• T2 Echo Measurement: Completed with expected dephasing profile\")\nif 't2_ramsey' in coherence_results:\n    print(\"• T2 Ramsey Measurement: Shows frequency stability and coherence\")\n\nprint(\"\\n📊 LLM Interpretation:\")\nprint(\"The coherence measurements show typical values for a superconducting transmon.\")\nprint(\"T1 > T2 relationship is maintained, indicating good system isolation.\")\nprint(\"Results are consistent with the theoretical expectations for this setup.\")\n\nprint(\"\\n✓ LLM-assisted experiment planning and analysis complete!\")"
  },
  {
   "cell_type": "markdown",
   "id": "fvr31lveund",
   "source": "## Advanced AI Features: Inspection Decorators and Adaptive Optimization\n\nLeeQ's AI system includes advanced features for real-time experiment monitoring and \nadaptive parameter optimization based on intermediate results.\n\n### Advanced Features:\n- **k_agents Inspection**: Real-time AI analysis during experiments\n- **Adaptive Calibration**: Dynamic parameter adjustment\n- **Intelligent Recommendations**: AI-driven next experiment suggestions  \n- **Performance Monitoring**: Continuous quality assessment",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "vfxbwujstc",
   "source": "# Advanced AI Example: Adaptive Parameter Optimization\nprint(\"🧠 Advanced AI Features Demonstration\")\nprint(\"=\"*50)\n\n# Mock k_agents inspection decorator for demonstration\ndef mock_ai_inspection_decorator(experiment_func):\n    \"\"\"Mock AI inspection decorator that monitors experiment progress.\"\"\"\n    def wrapper(*args, **kwargs):\n        print(f\"🔍 AI Inspector: Starting {experiment_func.__name__}\")\n        \n        # Simulate AI monitoring during experiment\n        result = experiment_func(*args, **kwargs)\n        \n        # Mock AI analysis of results\n        if 'rabi' in experiment_func.__name__.lower():\n            print(\"🤖 AI Analysis: Rabi oscillation detected, contrast = 85%\")\n            print(\"🎯 AI Suggestion: Consider 5% amplitude reduction for optimal fidelity\")\n        elif 't1' in experiment_func.__name__.lower():\n            print(\"🤖 AI Analysis: Exponential decay fitted, T1 = 68 ± 3 μs\")\n            print(\"🎯 AI Suggestion: T1 within expected range, no action needed\")\n        elif 'ramsey' in experiment_func.__name__.lower():\n            print(\"🤖 AI Analysis: Frequency drift detected: +0.05 MHz\")\n            print(\"🎯 AI Suggestion: Update drive frequency for next experiments\")\n            \n        return result\n    return wrapper\n\n# Example of AI-monitored experiments\n@mock_ai_inspection_decorator\ndef ai_monitored_rabi_experiment(dut):\n    \"\"\"Rabi experiment with AI monitoring.\"\"\"\n    return NormalisedRabi(dut_qubit=dut, step=0.01, stop=0.3, amp=0.2, update=False)\n\n@mock_ai_inspection_decorator  \ndef ai_monitored_t1_experiment(dut):\n    \"\"\"T1 experiment with AI monitoring.\"\"\"\n    return SimpleT1(qubit=dut, time_length=200, time_resolution=10)\n\n# Run AI-monitored experiments\nprint(\"\\n🔬 Running AI-Monitored Experiments:\")\nprint(\"\\n1. AI-Monitored Rabi Calibration:\")\nai_rabi = ai_monitored_rabi_experiment(dut)\n\nprint(\"\\n2. AI-Monitored T1 Measurement:\")\nai_t1 = ai_monitored_t1_experiment(dut)\n\n# Demonstrate adaptive parameter optimization\nprint(\"\\n🎯 Adaptive Parameter Optimization Demo:\")\n\nclass MockAdaptiveCalibrator:\n    \"\"\"Mock adaptive calibration system.\"\"\"\n    \n    def __init__(self, dut):\n        self.dut = dut\n        self.optimization_history = []\n        self.current_params = {\n            'rabi_amplitude': 0.55,\n            'frequency_offset': 0.0,\n            'drag_coefficient': 500\n        }\n    \n    def optimize_parameter(self, param_name, target_metric='fidelity'):\n        \"\"\"Mock adaptive parameter optimization.\"\"\"\n        print(f\"\\n🔄 Optimizing {param_name} for maximum {target_metric}...\")\n        \n        # Simulate parameter sweep and AI optimization\n        optimization_steps = [\n            (0.50, 0.987), (0.52, 0.991), (0.54, 0.994), \n            (0.55, 0.993), (0.53, 0.995)  # optimal at 0.53\n        ]\n        \n        print(\"AI Optimization Progress:\")\n        for i, (param_val, metric_val) in enumerate(optimization_steps):\n            print(f\"  Step {i+1}: {param_name} = {param_val:.3f} → {target_metric} = {metric_val:.3f}\")\n            \n        # Find optimal value\n        optimal_idx = max(range(len(optimization_steps)), \n                         key=lambda i: optimization_steps[i][1])\n        optimal_param, optimal_metric = optimization_steps[optimal_idx]\n        \n        print(f\"\\n🎯 Optimal {param_name}: {optimal_param:.3f}\")\n        print(f\"📈 Best {target_metric}: {optimal_metric:.3f}\")\n        \n        # Update parameters\n        self.current_params[param_name] = optimal_param\n        self.optimization_history.append({\n            'parameter': param_name,\n            'optimal_value': optimal_param,\n            'metric_achieved': optimal_metric\n        })\n        \n        return optimal_param, optimal_metric\n\n# Run adaptive optimization\nadaptive_cal = MockAdaptiveCalibrator(dut)\n\n# Optimize multiple parameters\nparameters_to_optimize = ['rabi_amplitude', 'drag_coefficient']\nfor param in parameters_to_optimize:\n    adaptive_cal.optimize_parameter(param)\n\n# Show optimization summary\nprint(\"\\n📊 Adaptive Optimization Summary:\")\nfor entry in adaptive_cal.optimization_history:\n    print(f\"• {entry['parameter']}: {entry['optimal_value']:.3f} \"\n          f\"(fidelity: {entry['metric_achieved']:.3f})\")\n\n# AI Recommendations for next experiments  \nprint(\"\\n🤖 AI Recommendations for Next Experiments:\")\nrecommendations = [\n    \"Run process tomography with optimized parameters\",\n    \"Perform randomized benchmarking to validate fidelity improvements\", \n    \"Test parameter stability over extended time periods\",\n    \"Implement two-qubit gates using optimized single-qubit parameters\"\n]\n\nfor i, rec in enumerate(recommendations, 1):\n    print(f\"{i}. {rec}\")\n\nprint(\"\\n✓ Advanced AI features demonstration complete!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You've completed the LeeQ tutorial series. You now have a solid foundation in:\n",
    "\n",
    "- LeeQ core concepts and simulation\n",
    "- Single and multi-qubit experiments\n",
    "- Complete calibration workflows\n",
    "- AI-assisted experiment generation\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Explore the following resources for deeper learning:\n",
    "\n",
    "- **Examples**: Check out `/notebooks/examples/` for specific experiment implementations\n",
    "- **Workflows**: See `/notebooks/workflows/` for complete experimental procedures\n",
    "- **Documentation**: Visit the full documentation for detailed API references"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}